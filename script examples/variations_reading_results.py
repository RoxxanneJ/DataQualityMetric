import numpy as np

models = ['logistic regression', 'knn', 'decision tree', 'random forest', 'ada boost', 'naive bayes', 'xgboost',
          'svc', 'gaussian process', 'mlp', 'sgd', 'gradient boosting']

crt_names = ['missing', 'fuzzing', 'outlier']

# Reading intermediate results (accuracy and f1 scores when 5% of the errors in crt_names are injected in data)
# generated by the example scripts of DQ computation

# When trusted test data are available accuracy and f1 score are computed once for each error type and model,
# which results in 36 (3x12) scores
ex_spambase_accs = np.load("output/variations/example_spambase_15_outlier_var_accs.npy")
ex_spambase_f1s = np.load("output/variations/example_spambase_15_outlier_var_f1s.npy")

ex_statlog_accs = np.load("output/variations/example_statlog_10_outlier_var_accs.npy")
ex_statlog_f1s = np.load("output/variations/example_statlog_10_outlier_var_f1s.npy")

# When trusted test data are not available accuracy and f1 score are computed for 30 samplings of train and test for
# each error type and model, which results in 1080 (3x12x30) scores
ex_cancer_accs = np.load("output/variations/example_cancer_5_missing_var_accs.npy")
ex_cancer_f1s = np.load("output/variations/example_cancer_5_missing_var_f1s.npy")

ex_iris_accs = np.load("output/variations/example_iris_30_missing_noTest_var_accs.npy")
ex_iris_f1s = np.load("output/variations/example_iris_30_missing_noTest_var_f1s.npy")